{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce48bf9b-b1ed-49e9-984c-3202ae81c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import nltk\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from contractions import fix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e28ae8-6bd0-4e6c-8c4b-826e2003b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('tweet/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line)) \n",
    "f.close()\n",
    "\n",
    "emotion = pd.read_csv('tweet/emotion.csv')\n",
    "data_identification = pd.read_csv('tweet/data_identification.csv')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.1, random_state=42)\n",
    "train_data_sample.to_pickle(\"train_dsample.pkl\")\n",
    "train_df = pd.read_pickle(\"train_dsample.pkl\")\n",
    "\n",
    "test_data.to_pickle(\"test_d.pkl\")\n",
    "test_df = pd.read_pickle(\"test_d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f32ee6-46b1-4975-a8db-e3ff29e1b2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d305cfc55e040248ca4cb1b86e09ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/144918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ac50810f747c798de7841d125d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/411972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import wordnet\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Ë°®ÊÉÖÁ¨¶ËôüÊõøÊèõË©ûÂÖ∏\n",
    "emoji_dict = {\n",
    "    'üòÇ': '[joy]', '‚ù§Ô∏è': '[love]', 'üòç': '[adoration]', 'üò≠': '[cry]',\n",
    "    '‚ù§': '[care]', 'üòä': '[happy]', 'üôè': '[pray]', 'üòò': '[kiss]',\n",
    "    'üíï': '[love_each_other]', 'üî•': '[fire]', 'üò©': '[weary]',\n",
    "    'ü§î': '[think]', 'üíØ': '[perfect]', 'üíô': '[loyalty]',\n",
    "    'üôÑ': '[annoyed]', 'üòÅ': '[happy]', 'üôå': '[celebrate]',\n",
    "    'üôèüèæ': '[pray]', 'üëç': '[approve]', 'üôèüèΩ': '[pray]'\n",
    "}\n",
    "\n",
    "# Define a dictionary for common Twitter abbreviations/slangs\n",
    "slang_dict = {\n",
    "    \"lol\": \"laugh out_loud\",\n",
    "    \"u\": \"you\",\n",
    "    \"idk\": \"I do not know\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"lmao\": \"laugh my_ass_off\",\n",
    "    \"lmfao\": \"laugh my_ass_off\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"brb\": \"be right back\"\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "# È†êËôïÁêÜÂáΩÊï∏\n",
    "def preprocess_text(text):\n",
    "    # ÊõøÊèõ emoji\n",
    "    for emj, keyword in emoji_dict.items():\n",
    "        text = text.replace(emj, keyword)\n",
    "    text = emoji.replace_emoji(text, replace='')  # ÁßªÈô§ÂÖ∂‰ªñ emoji\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # ÁßªÈô§Á∂≤ÂùÄ\n",
    "    text = re.sub(r'RT[\\s]+', '', text)  # Remove RT\n",
    "    text = text.replace('<LH>', '')\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # ÁßªÈô§ @user Âíå hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", '', text)  # ÁßªÈô§ÁâπÊÆäÂ≠óÂÖÉ\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s!?]', '', text)\n",
    "    text = re.sub(r'not\\s+(\\w+)', r'not_\\1', text)\n",
    "    \n",
    "    wds = text.split()\n",
    "    tweet = \" \".join([slang_dict[wd.lower()] if wd.lower() in slang_dict else wd for wd in wds])\n",
    "    \n",
    "    text = fix(text)\n",
    "    #text = str(TextBlob(text).correct())\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(wd) for wd in text.split()])\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    return ' '.join([word for word in words if word not in stop_words])\n",
    "\n",
    "# Ê∏ÖÁêÜË®ìÁ∑¥ËàáÊ∏¨Ë©¶Ë≥áÊñô\n",
    "train_df['clean_text'] = train_df['text'].swifter.apply(preprocess_text)\n",
    "test_df['clean_text'] = test_df['text'].swifter.apply(preprocess_text)\n",
    "\n",
    "# Êâì‰∫ÇË®ìÁ∑¥Ë≥áÊñô\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4435f750-620b-4b98-b304-809e3b4608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Â∞á hashtags ÁµÑÂêàÊàêÂ≠ó‰∏≤\n",
    "train_df['hashtags'] = train_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "test_df['hashtags'] = test_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# Ë®ìÁ∑¥ TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "tfidf_train = tfidf.fit_transform(train_df['hashtags'].fillna(''))\n",
    "tfidf_test = tfidf.transform(test_df['hashtags'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054ba0db-2d16-4490-9b8b-b471235cfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Â∞áÊØèÊÆµÊñáÂ≠óËΩâÁÇ∫Ë©ûÂàóË°®\n",
    "train_sentences = train_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "test_sentences = test_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# Ë®ìÁ∑¥ Word2Vec Ê®°Âûã\n",
    "w2v_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# Â∞áÊñáÂ≠óËΩâÊèõÁÇ∫ÂêëÈáèÂπ≥ÂùáÂÄº\n",
    "def sentence_to_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "train_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in train_sentences])\n",
    "test_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in test_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7914812d-4c9c-4b5a-90b1-4871128da055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791c40d34f104271b85b5196ce52d37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/144918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95af69b9e52f4a17bdaf17a8c10c9953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/411972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÂàÜÊâπËôïÁêÜÔºöBERT ÂµåÂÖ•\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Â∞áÊ®°ÂûãÁßªËá≥ GPU\n",
    "model.to('cuda')\n",
    "\n",
    "def extract_bert_embeddings(text_series, batch_size=32):\n",
    "    def process_batch(batch_texts):\n",
    "        encodings = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        for key in encodings:\n",
    "            encodings[key] = encodings[key].to('cuda')  # ÁßªÂà∞ GPU\n",
    "        outputs = model(**encodings)\n",
    "        return outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()  # ÂõûÂà∞ CPU ÈÄ≤Ë°å NumPy ËôïÁêÜ\n",
    "\n",
    "    embeddings = (\n",
    "        text_series\n",
    "        .swifter.apply(lambda text: process_batch([text])[0])  # ÂñÆ‰∏ÄÊñáÊú¨ËôïÁêÜ\n",
    "        .to_numpy()\n",
    "    )\n",
    "    return np.stack(embeddings)\n",
    "\n",
    "bert_train = extract_bert_embeddings(train_df['text'])\n",
    "bert_test = extract_bert_embeddings(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1ab0fe-97d2-40b0-83f6-b85b270697d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\t1070\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e4554aeb5a4d52b97a08b2b3bb12e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/144918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0aacbb6a474a38900d14b7627ae848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/411972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‰ΩøÁî® NRC Lexicon ÁâπÂæµ\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def extract_sentiment_features(text_series):\n",
    "    sentiment_scores = text_series.swifter.apply(lambda text: sid.polarity_scores(text))\n",
    "    return pd.DataFrame(list(sentiment_scores))\n",
    "\n",
    "sentiment_train = extract_sentiment_features(train_df['text'])\n",
    "sentiment_test = extract_sentiment_features(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a42507d-9fa8-4955-9a8f-908f732d650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_text    object\n",
      "dtype: object\n",
      "                                          clean_text\n",
      "0  {'neg': 0.355, 'neu': 0.376, 'pos': 0.269, 'co...\n",
      "1  {'neg': 0.388, 'neu': 0.432, 'pos': 0.18, 'com...\n",
      "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
      "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
      "4  {'neg': 0.0, 'neu': 0.431, 'pos': 0.569, 'comp...\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_train.dtypes)\n",
    "print(sentiment_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97402fc-72b5-440c-841e-9767497417e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âêà‰ΩµÂµåÂÖ•ËàáÊÉÖÁ∑íÁâπÂæµ\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# ËΩâÊèõÁÇ∫ GPU ÂºµÈáè‰∏¶Â†ÜÁñä\n",
    "train_features = torch.cat([\n",
    "    torch.tensor(tfidf_train.toarray(), dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(train_text_vectors, dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(bert_train, dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(sentiment_train.values.astype(np.float32), dtype=torch.float32).to('cuda')\n",
    "], dim=1)\n",
    "\n",
    "test_features = torch.cat([\n",
    "    torch.tensor(tfidf_test.toarray(), dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(test_text_vectors, dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(bert_test, dtype=torch.float32).to('cuda'),\n",
    "    torch.tensor(sentiment_test.values.astype(np.float32), dtype=torch.float32).to('cuda')\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72fbbc3-4c11-4884-892c-e2ded24e592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê®ôÁ±§Á∑®Á¢º\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['emotion'])\n",
    "#y_test = label_encoder.transform(test_df['emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f2e6519-7aa5-4878-8152-ab205a18700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê®°ÂûãÂÆöÁæ©\n",
    "import xgboost as xgb\n",
    "from torch import nn\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=len(label_encoder.classes_), \n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    tree_method='auto'\n",
    ")\n",
    "# xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "\n",
    "# Ê®°ÂûãÂÆöÁæ©ÔºöLSTM + Attention\n",
    "# class LSTMWithAttention(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#         super(LSTMWithAttention, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "#         self.attention = nn.Linear(hidden_dim * 2, 1)  # Linear layer for attention scores\n",
    "#         self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Final output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         lstm_out, _ = self.lstm(x)  # lstm_out shape: (batch_size, seq_len, hidden_dim*2)\n",
    "        \n",
    "#         # Compute attention scores (shape: [batch_size, seq_len, 1])\n",
    "#         attention_scores = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "        \n",
    "#         # Apply attention weights to LSTM output\n",
    "#         attended_output = torch.sum(attention_scores * lstm_out, dim=1)  # Summing over the sequence length\n",
    "\n",
    "#         # Pass through the final fully connected layer\n",
    "#         output = self.fc(attended_output)\n",
    "#         return output\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure x is 3D: [batch_size, sequence_length, features]\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)  # Add sequence dimension if missing\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = self.attention(lstm_out).squeeze(-1)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        \n",
    "        # Weighted sum of LSTM outputs\n",
    "        attended_output = torch.sum(attention_weights.unsqueeze(-1) * lstm_out, dim=1)\n",
    "        \n",
    "        return self.fc(attended_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8187ae-25f9-449e-b8b0-62bcb56fec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞áÁâπÂæµËàáÊ®ôÁ±§ÈÄ≤Ë°åÂàÜÂâ≤\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    train_features,  # Âæû train_features ‰∏≠ÂäÉÂàÜ\n",
    "    y_train, # Â∑≤Á∑®Á¢ºÁöÑÁõÆÊ®ôÂÄº\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train  # Á¢∫‰øùÈ°ûÂà•ÂàÜ‰Ωà‰∏ÄËá¥\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a952d502-60fa-417c-8ba4-597245d8f2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([579672, 1372]) (579672,)\n",
      "torch.Size([144919, 1372]) (144919,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_split.shape, y_train_split.shape)\n",
    "print(X_val_split.shape, y_val_split.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c25272-8bb1-45da-ade4-0f9aaa2358d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 7, ..., 7, 3, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_split_encoded = label_encoder.fit_transform(y_train_split)\n",
    "y_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7eec608-8250-4260-b692-b5380b888e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "train_features_cpu = train_features.cpu().numpy()  # Move to CPU and convert to NumPy\n",
    "y_train_cpu = y_train\n",
    "\n",
    "# Check for NaN or infinity values in the features and labels\n",
    "print(np.any(np.isnan(train_features_cpu)))  # Check for NaNs in the features\n",
    "print(np.any(np.isnan(y_train_cpu)))         # Check for NaNs in the labels\n",
    "print(np.any(np.isinf(train_features_cpu)))  # Check for infinities in the features\n",
    "print(np.any(np.isinf(y_train_cpu)))         # Check for infinities in the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07db3154-97cb-49af-b834-bf669348f01f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[0;32m      4\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(train_features, label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# xgb_model.fit(\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     X_train_split, y_train_split,\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#     eval_set=[(X_val_split, y_val_split)],  # È©óË≠âÈõÜË©ï‰º∞\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#xgb_model.fit(X_train_split, y_train_split)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#y_pred_val_encoded = xgb_model.predict(X_val_split)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "# Ê®°ÂûãË®ìÁ∑¥ËàáË©ï‰º∞\n",
    "# 1. XGBoost Ê®°Âûã\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "dtrain = xgb.DMatrix(train_features, label=y_train)\n",
    "# xgb_model.fit(\n",
    "#     X_train_split, y_train_split,\n",
    "#     eval_set=[(X_val_split, y_val_split)],  # È©óË≠âÈõÜË©ï‰º∞\n",
    "#     verbose=True\n",
    "# )\n",
    "#xgb_model.fit(X_train_split, y_train_split)\n",
    "#y_pred_val_encoded = xgb_model.predict(X_val_split)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Â∞áÊï∏ÂÄºÊ®ôÁ±§ËΩâÂõûÊñáÂ≠óÊ®ôÁ±§\n",
    "y_pred_val = label_encoder.inverse_transform(y_pred_val_encoded)\n",
    "y_val_split_text = label_encoder.inverse_transform(y_val_split)\n",
    "\n",
    "# Ë©ï‰º∞Ê®°Âûã\n",
    "print(confusion_matrix(y_val_split_text, y_pred_val))\n",
    "print(classification_report(y_val_split_text, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da1b26-e4fc-493e-baae-ea7b47c40103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfba7edf-98d0-4645-a783-f283e4a6f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t1070\\AppData\\Local\\Temp\\ipykernel_19048\\3022464967.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_train_split, dtype=torch.float32),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Average Loss: 0.7421766256730004\n",
      "Epoch 2/5, Average Loss: 0.7017438596547917\n",
      "Epoch 3/5, Average Loss: 0.6837248608342462\n",
      "Epoch 4/5, Average Loss: 0.6710774905850075\n",
      "Epoch 5/5, Average Loss: 0.6609893236499513\n"
     ]
    }
   ],
   "source": [
    "# 2. LSTM+Attention Ê®°Âûã\n",
    "# ÊßãÂª∫ DataLoader\n",
    "batch_size = 16\n",
    "accumulation_steps = 2\n",
    "num_epochs = 5\n",
    "\n",
    "# Create dataset and loader\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train_split, dtype=torch.float32), \n",
    "    torch.tensor(y_train_split, dtype=torch.long)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "lstm_attention_model = LSTMWithAttention(\n",
    "    input_dim=X_train_split.shape[1], \n",
    "    hidden_dim=64,  # Reduced hidden dimension \n",
    "    output_dim=len(label_encoder.classes_)\n",
    ").to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm_attention_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    lstm_attention_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for i, (batch_features, batch_labels) in enumerate(train_loader):\n",
    "        batch_features = batch_features.to('cuda')\n",
    "        batch_labels = batch_labels.to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = lstm_attention_model(batch_features)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, batch_labels) / accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {epoch_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9368ffc-ad03-4968-8c49-a8dd78d3ac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t1070\\AppData\\Local\\Temp\\ipykernel_19048\\3508474324.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X_val_split, dtype=torch.float32),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Confusion Matrix:\n",
      "[[  92   61  100   10  251  265    2   23]\n",
      " [   3 2285   94   31 1837  369    7  285]\n",
      " [  28  146  703   31  863  908    7   85]\n",
      " [   1   94   51  273  585  221    3   42]\n",
      " [   5  659  170   55 8010  769   12  618]\n",
      " [  23  178  351   49 1299 1858    3   94]\n",
      " [   4   66   70   15  419  245  102   32]\n",
      " [   5  397  103   24 2214  334    3 1042]]\n",
      "\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.11      0.19       804\n",
      "           1       0.59      0.47      0.52      4911\n",
      "           2       0.43      0.25      0.32      2771\n",
      "           3       0.56      0.21      0.31      1270\n",
      "           4       0.52      0.78      0.62     10298\n",
      "           5       0.37      0.48      0.42      3855\n",
      "           6       0.73      0.11      0.19       953\n",
      "           7       0.47      0.25      0.33      4122\n",
      "\n",
      "    accuracy                           0.50     28984\n",
      "   macro avg       0.53      0.33      0.36     28984\n",
      "weighted avg       0.51      0.50      0.47     28984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Move test features to CUDA and ensure correct tensor type\n",
    "# val_features_tensor = torch.tensor(X_val_split, dtype=torch.float32).to('cuda')\n",
    "\n",
    "# # Evaluate LSTM model\n",
    "# lstm_attention_model.eval()\n",
    "# with torch.no_grad():\n",
    "#     lstm_preds = torch.argmax(lstm_attention_model(val_features_tensor), dim=1).cpu().numpy()\n",
    "\n",
    "# print(\"LSTM Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_val_split, lstm_preds))\n",
    "# print(\"\\nLSTM Classification Report:\")\n",
    "# print(classification_report(y_val_split, lstm_preds))\n",
    "\n",
    "# Validation loop\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(X_val_split, dtype=torch.float32), \n",
    "    torch.tensor(y_val_split, dtype=torch.long)\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "lstm_attention_model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in val_loader:\n",
    "        batch_features = batch_features.to('cuda')\n",
    "        outputs = lstm_attention_model(batch_features)\n",
    "        batch_preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        val_preds.extend(batch_preds)\n",
    "        val_true.extend(batch_labels.numpy())\n",
    "\n",
    "print(\"LSTM Confusion Matrix:\")\n",
    "print(confusion_matrix(val_true, val_preds))\n",
    "print(\"\\nLSTM Classification Report:\")\n",
    "print(classification_report(val_true, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981dd80-ee3a-4fab-8b65-f059f39d14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Ensemble Voting\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_model),\n",
    "    ('lstm', lstm_attention_model)  # Ê≥®ÊÑèÔºöÈúÄË™øÊï¥Ê°ÜÊû∂‰ª•ÊîØÊåÅ VotingClassifier\n",
    "], voting='hard')\n",
    "\n",
    "voting_preds = [np.argmax(np.bincount([x, y])) for x, y in zip(xgb_preds, lstm_preds)]\n",
    "\n",
    "print(\"Voting Classifier Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, voting_preds))\n",
    "print(\"\\nVoting Classifier Classification Report:\")\n",
    "print(classification_report(y_test, voting_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be57d944-bac7-4b45-a231-05c446c22839",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['emotion'] = label_encoder.inverse_transform(voting_preds)\n",
    "submission = test_data[['tweet_id', 'emotion']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15c5f72b-f4af-4b02-8ac1-010059f19f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\t1070\\AppData\\Local\\Temp\\ipykernel_19048\\3397346809.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_features_tensor = torch.tensor(test_features, dtype=torch.float32).to('cuda')\n"
     ]
    }
   ],
   "source": [
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32).to('cuda')\n",
    "\n",
    "# Predict on test set\n",
    "lstm_attention_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = torch.argmax(lstm_attention_model(test_features_tensor), dim=1).cpu().numpy()\n",
    "\n",
    "# Inverse transform predictions\n",
    "test_df['emotion'] = label_encoder.inverse_transform(y_test_pred)\n",
    "\n",
    "# Output submission\n",
    "submission = test_df[['tweet_id', 'emotion']]\n",
    "submission.to_csv('lstm_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977031e-10a3-4f61-a710-ec6d7114d21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781f4d0-0f49-42ce-947a-22359e258a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.fit_transform(train_data['emotion'])\n",
    "y_test = label_encoder.transform(test_data['emotion'])\n",
    "\n",
    "X_train = np.array(train_data['bert_embeddings'].tolist())\n",
    "X_test = np.array(test_data['bert_embeddings'].tolist())\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Ë®ìÁ∑¥Ê®°Âûã\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_encoder.classes_)\n",
    "\n",
    "model = LSTMWithAttention(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3216ee3-3dcc-46bd-8439-2555eb3b360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('xgb', xgb_model),\n",
    "    ('lstm', lstm_attention_model)\n",
    "], voting='hard')\n",
    "\n",
    "# Ê≥®ÊÑèÔºöLSTM + Attention ÁöÑË®ìÁ∑¥ÈúÄË¶Å‰ΩøÁî® DataLoader Âíå‰πãÂâçÁöÑË®ìÁ∑¥Á®ãÂºèÁ¢º„ÄÇ\n",
    "# Voting ÊúÉÂ∞á XGBoost Âíå LSTM ÁöÑÈ†êÊ∏¨ÁµêÂêà\n",
    "voting_clf.fit(train_features, y_train)\n",
    "final_predictions = voting_clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90bbd4f5-4b16-4947-a04d-f886212ac8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  460   196   638    37  1737   769     4    38]\n",
      " [   32 11747   880   137 10413  1243    14   486]\n",
      " [   70   635  4319   152  5325  3074     9   120]\n",
      " [    6   455   431  1623  3175   653     7    56]\n",
      " [   32  3258  1455   305 42798  2354    28  1251]\n",
      " [   82   979  2585   204  8177  6952    17   198]\n",
      " [    8   235   599    53  2447   781   614    72]\n",
      " [   12  1950   811    78 12834  1042    14  3753]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.12      0.20      3879\n",
      "anticipation       0.60      0.47      0.53     24952\n",
      "     disgust       0.37      0.32      0.34     13704\n",
      "        fear       0.63      0.25      0.36      6406\n",
      "         joy       0.49      0.83      0.62     51481\n",
      "     sadness       0.41      0.36      0.39     19194\n",
      "    surprise       0.87      0.13      0.22      4809\n",
      "       trust       0.63      0.18      0.28     20494\n",
      "\n",
      "    accuracy                           0.50    144919\n",
      "   macro avg       0.58      0.33      0.37    144919\n",
      "weighted avg       0.53      0.50      0.46    144919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Â∞áÊï∏ÂÄºÊ®ôÁ±§ËΩâÂõûÊñáÂ≠óÊ®ôÁ±§\n",
    "y_pred_val = label_encoder.inverse_transform(y_pred_val_encoded)\n",
    "y_val_split_text = label_encoder.inverse_transform(y_val_split)\n",
    "\n",
    "# Ë©ï‰º∞Ê®°Âûã\n",
    "print(confusion_matrix(y_val_split_text, y_pred_val))\n",
    "print(classification_report(y_val_split_text, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9158e6e2-5878-4afe-9677-e61089c837da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# È†êÊ∏¨Ê∏¨Ë©¶ÈõÜ\n",
    "y_test_pred_encoded = xgb_model.predict(X_test)\n",
    "test_df['emotion'] = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "# Ëº∏Âá∫ÁÇ∫ submission.csv\n",
    "submission = test_df[['tweet_id', 'emotion']]\n",
    "submission.to_csv('submission_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
