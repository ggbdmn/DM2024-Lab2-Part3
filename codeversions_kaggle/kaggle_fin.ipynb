{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce48bf9b-b1ed-49e9-984c-3202ae81c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e28ae8-6bd0-4e6c-8c4b-826e2003b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('tweet/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line)) \n",
    "f.close()\n",
    "\n",
    "emotion = pd.read_csv('tweet/emotion.csv')\n",
    "data_identification = pd.read_csv('tweet/data_identification.csv')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.5, random_state=42)\n",
    "train_data_sample.to_pickle(\"train_dsample.pkl\")\n",
    "train_df = pd.read_pickle(\"train_dsample.pkl\")\n",
    "\n",
    "test_data.to_pickle(\"test_d.pkl\")\n",
    "test_df = pd.read_pickle(\"test_d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f32ee6-46b1-4975-a8db-e3ff29e1b2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dee852a09f4739a6c5ad2dd63eccb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/724591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf02d87363cb48f1b07be2bc9b5f58c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/411972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 表情符號替換詞典\n",
    "emoji_dict = {\n",
    "    '😂': '[joy]', '❤️': '[love]', '😍': '[adoration]', '😭': '[cry]',\n",
    "    '❤': '[care]', '😊': '[happy]', '🙏': '[pray]', '😘': '[kiss]',\n",
    "    '💕': '[love_each_other]', '🔥': '[fire]', '😩': '[weary]',\n",
    "    '🤔': '[think]', '💯': '[perfect]', '💙': '[loyalty]',\n",
    "    '🙄': '[annoyed]', '😁': '[happy]', '🙌': '[celebrate]',\n",
    "    '🙏🏾': '[pray]', '👍': '[approve]', '🙏🏽': '[pray]'\n",
    "}\n",
    "\n",
    "# 預處理函數\n",
    "def preprocess_text(text):\n",
    "    # 替換 emoji\n",
    "    for emj, keyword in emoji_dict.items():\n",
    "        text = text.replace(emj, keyword)\n",
    "    text = emoji.replace_emoji(text, replace='')  # 移除其他 emoji\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # 移除網址\n",
    "    text = text.replace('<LH>', '')\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # 移除 @user 和 hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", '', text)  # 移除特殊字元\n",
    "    text = text.lower()  # 小寫化\n",
    "    text = text.strip()\n",
    "    words = word_tokenize(text)\n",
    "    return ' '.join([word for word in words if word not in stop_words])\n",
    "\n",
    "# 清理訓練與測試資料\n",
    "train_df['clean_text'] = train_df['text'].swifter.apply(preprocess_text)\n",
    "test_df['clean_text'] = test_df['text'].swifter.apply(preprocess_text)\n",
    "\n",
    "# 打亂訓練資料\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4435f750-620b-4b98-b304-809e3b4608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 將 hashtags 組合成字串\n",
    "train_df['hashtags'] = train_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "test_df['hashtags'] = test_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# 訓練 TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "tfidf_train = tfidf.fit_transform(train_df['hashtags'])\n",
    "tfidf_test = tfidf.transform(test_df['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054ba0db-2d16-4490-9b8b-b471235cfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# 將每段文字轉為詞列表\n",
    "train_sentences = train_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "test_sentences = test_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# 訓練 Word2Vec 模型\n",
    "w2v_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# 將文字轉換為向量平均值\n",
    "def sentence_to_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "train_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in train_sentences])\n",
    "test_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in test_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72fbbc3-4c11-4884-892c-e2ded24e592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# 將 TF-IDF 與 Word2Vec 合併\n",
    "X_train = hstack([tfidf_train, train_text_vectors])\n",
    "X_test = hstack([tfidf_test, test_text_vectors])\n",
    "\n",
    "# 訓練標籤\n",
    "y_train = train_df['emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7c12dd-8411-4f7f-be40-8a59d27463c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 將文字標籤轉換為數值\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# 分割訓練與驗證資料\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "xgb_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# 預測驗證集\n",
    "y_pred_val_encoded = xgb_model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bbd4f5-4b16-4947-a04d-f886212ac8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  450   182   580    51  1691   875     1    49]\n",
      " [   24 11887   854   140 10375  1247    15   410]\n",
      " [   60   564  4299   150  5309  3195     6   121]\n",
      " [    7   428   461  1627  3183   636     4    60]\n",
      " [   31  3197  1539   319 42950  2349    16  1080]\n",
      " [   63   915  2647   208  8139  7035    12   175]\n",
      " [   12   229   590    57  2427   824   616    54]\n",
      " [   18  1988   787   104 12959  1045    10  3583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.12      0.20      3879\n",
      "anticipation       0.61      0.48      0.54     24952\n",
      "     disgust       0.37      0.31      0.34     13704\n",
      "        fear       0.61      0.25      0.36      6406\n",
      "         joy       0.49      0.83      0.62     51481\n",
      "     sadness       0.41      0.37      0.39     19194\n",
      "    surprise       0.91      0.13      0.22      4809\n",
      "       trust       0.65      0.17      0.28     20494\n",
      "\n",
      "    accuracy                           0.50    144919\n",
      "   macro avg       0.59      0.33      0.37    144919\n",
      "weighted avg       0.54      0.50      0.46    144919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 將數值標籤轉回文字標籤\n",
    "y_pred_val = label_encoder.inverse_transform(y_pred_val_encoded)\n",
    "y_val_split_text = label_encoder.inverse_transform(y_val_split)\n",
    "\n",
    "# 評估模型\n",
    "print(confusion_matrix(y_val_split_text, y_pred_val))\n",
    "print(classification_report(y_val_split_text, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9158e6e2-5878-4afe-9677-e61089c837da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測測試集\n",
    "y_test_pred_encoded = xgb_model.predict(X_test)\n",
    "test_df['emotion'] = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "# 輸出為 submission.csv\n",
    "submission = test_df[['id', 'emotion']]\n",
    "submission.to_csv('submission_fin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7869f0-8b44-4057-aed1-dcc8d2afc5c7",
   "metadata": {},
   "source": [
    "1. 你認為使用xgboost是好方法嗎 還是有別的更好的辦法 code要做那些修改\n",
    "2. 你認為降維會提高最後的結果嗎 應該在哪裡降\n",
    "3. 你認為前處理還有什麼可以更加強的做法嗎 例如正則化之類的 或是其他 請提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774f8cee-32b9-4845-8b4a-e70f97acb0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a  anticipation\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80       sadness\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"submission_fin.csv\")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bbfcc65-9542-4ee8-9b17-feb48ffe234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a         trust\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80           joy\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.read_csv(\"submission.csv\")\n",
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc28a3c1-d861-48e9-a0c5-232db2e39bd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 找出兩個 column 中獨有的值\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m unique_to_df1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(sub1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m unique_to_df2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sub1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_to_df1:\n",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# 找出兩個 column 中獨有的值\n",
    "unique_to_df1 = set(sub['id']) - set(sub1['id'])\n",
    "unique_to_df2 = set(sub1['id']) - set(sub['id'])\n",
    "\n",
    "if unique_to_df1:\n",
    "    print(f\"sub.csv 中有 sub1.csv 沒有的值：{unique_to_df1}\")\n",
    "if unique_to_df2:\n",
    "    print(f\"sub1.csv 的  column 中有 sub.csv 沒有的值：{unique_to_df2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30b011-8854-4548-8ee5-430209e6cf24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
