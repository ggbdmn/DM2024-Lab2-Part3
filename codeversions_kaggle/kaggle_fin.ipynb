{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce48bf9b-b1ed-49e9-984c-3202ae81c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e28ae8-6bd0-4e6c-8c4b-826e2003b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('tweet/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line)) \n",
    "f.close()\n",
    "\n",
    "emotion = pd.read_csv('tweet/emotion.csv')\n",
    "data_identification = pd.read_csv('tweet/data_identification.csv')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_identification, on='tweet_id', how='left')\n",
    "\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "\n",
    "train_data = train_data.merge(emotion, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)\n",
    "\n",
    "train_data_sample = train_data.sample(frac=0.5, random_state=42)\n",
    "train_data_sample.to_pickle(\"train_dsample.pkl\")\n",
    "train_df = pd.read_pickle(\"train_dsample.pkl\")\n",
    "\n",
    "test_data.to_pickle(\"test_d.pkl\")\n",
    "test_df = pd.read_pickle(\"test_d.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f32ee6-46b1-4975-a8db-e3ff29e1b2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dee852a09f4739a6c5ad2dd63eccb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/724591 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf02d87363cb48f1b07be2bc9b5f58c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/411972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swifter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# è¡¨æƒ…ç¬¦è™Ÿæ›¿æ›è©å…¸\n",
    "emoji_dict = {\n",
    "    'ğŸ˜‚': '[joy]', 'â¤ï¸': '[love]', 'ğŸ˜': '[adoration]', 'ğŸ˜­': '[cry]',\n",
    "    'â¤': '[care]', 'ğŸ˜Š': '[happy]', 'ğŸ™': '[pray]', 'ğŸ˜˜': '[kiss]',\n",
    "    'ğŸ’•': '[love_each_other]', 'ğŸ”¥': '[fire]', 'ğŸ˜©': '[weary]',\n",
    "    'ğŸ¤”': '[think]', 'ğŸ’¯': '[perfect]', 'ğŸ’™': '[loyalty]',\n",
    "    'ğŸ™„': '[annoyed]', 'ğŸ˜': '[happy]', 'ğŸ™Œ': '[celebrate]',\n",
    "    'ğŸ™ğŸ¾': '[pray]', 'ğŸ‘': '[approve]', 'ğŸ™ğŸ½': '[pray]'\n",
    "}\n",
    "\n",
    "# é è™•ç†å‡½æ•¸\n",
    "def preprocess_text(text):\n",
    "    # æ›¿æ› emoji\n",
    "    for emj, keyword in emoji_dict.items():\n",
    "        text = text.replace(emj, keyword)\n",
    "    text = emoji.replace_emoji(text, replace='')  # ç§»é™¤å…¶ä»– emoji\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # ç§»é™¤ç¶²å€\n",
    "    text = text.replace('<LH>', '')\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # ç§»é™¤ @user å’Œ hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", '', text)  # ç§»é™¤ç‰¹æ®Šå­—å…ƒ\n",
    "    text = text.lower()  # å°å¯«åŒ–\n",
    "    text = text.strip()\n",
    "    words = word_tokenize(text)\n",
    "    return ' '.join([word for word in words if word not in stop_words])\n",
    "\n",
    "# æ¸…ç†è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™\n",
    "train_df['clean_text'] = train_df['text'].swifter.apply(preprocess_text)\n",
    "test_df['clean_text'] = test_df['text'].swifter.apply(preprocess_text)\n",
    "\n",
    "# æ‰“äº‚è¨“ç·´è³‡æ–™\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4435f750-620b-4b98-b304-809e3b4608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# å°‡ hashtags çµ„åˆæˆå­—ä¸²\n",
    "train_df['hashtags'] = train_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "test_df['hashtags'] = test_df['hashtags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "# è¨“ç·´ TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=500, stop_words='english')\n",
    "tfidf_train = tfidf.fit_transform(train_df['hashtags'])\n",
    "tfidf_test = tfidf.transform(test_df['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "054ba0db-2d16-4490-9b8b-b471235cfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# å°‡æ¯æ®µæ–‡å­—è½‰ç‚ºè©åˆ—è¡¨\n",
    "train_sentences = train_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "test_sentences = test_df['clean_text'].apply(lambda x: x.split()).tolist()\n",
    "\n",
    "# è¨“ç·´ Word2Vec æ¨¡å‹\n",
    "w2v_model = Word2Vec(sentences=train_sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "# å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡å¹³å‡å€¼\n",
    "def sentence_to_vector(sentence, model):\n",
    "    vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "train_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in train_sentences])\n",
    "test_text_vectors = np.array([sentence_to_vector(sent, w2v_model) for sent in test_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72fbbc3-4c11-4884-892c-e2ded24e592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# å°‡ TF-IDF èˆ‡ Word2Vec åˆä½µ\n",
    "X_train = hstack([tfidf_train, train_text_vectors])\n",
    "X_test = hstack([tfidf_test, test_text_vectors])\n",
    "\n",
    "# è¨“ç·´æ¨™ç±¤\n",
    "y_train = train_df['emotion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7c12dd-8411-4f7f-be40-8a59d27463c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# å°‡æ–‡å­—æ¨™ç±¤è½‰æ›ç‚ºæ•¸å€¼\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# åˆ†å‰²è¨“ç·´èˆ‡é©—è­‰è³‡æ–™\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# è¨“ç·´æ¨¡å‹\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_))\n",
    "xgb_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# é æ¸¬é©—è­‰é›†\n",
    "y_pred_val_encoded = xgb_model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90bbd4f5-4b16-4947-a04d-f886212ac8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  450   182   580    51  1691   875     1    49]\n",
      " [   24 11887   854   140 10375  1247    15   410]\n",
      " [   60   564  4299   150  5309  3195     6   121]\n",
      " [    7   428   461  1627  3183   636     4    60]\n",
      " [   31  3197  1539   319 42950  2349    16  1080]\n",
      " [   63   915  2647   208  8139  7035    12   175]\n",
      " [   12   229   590    57  2427   824   616    54]\n",
      " [   18  1988   787   104 12959  1045    10  3583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.12      0.20      3879\n",
      "anticipation       0.61      0.48      0.54     24952\n",
      "     disgust       0.37      0.31      0.34     13704\n",
      "        fear       0.61      0.25      0.36      6406\n",
      "         joy       0.49      0.83      0.62     51481\n",
      "     sadness       0.41      0.37      0.39     19194\n",
      "    surprise       0.91      0.13      0.22      4809\n",
      "       trust       0.65      0.17      0.28     20494\n",
      "\n",
      "    accuracy                           0.50    144919\n",
      "   macro avg       0.59      0.33      0.37    144919\n",
      "weighted avg       0.54      0.50      0.46    144919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# å°‡æ•¸å€¼æ¨™ç±¤è½‰å›æ–‡å­—æ¨™ç±¤\n",
    "y_pred_val = label_encoder.inverse_transform(y_pred_val_encoded)\n",
    "y_val_split_text = label_encoder.inverse_transform(y_val_split)\n",
    "\n",
    "# è©•ä¼°æ¨¡å‹\n",
    "print(confusion_matrix(y_val_split_text, y_pred_val))\n",
    "print(classification_report(y_val_split_text, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9158e6e2-5878-4afe-9677-e61089c837da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é æ¸¬æ¸¬è©¦é›†\n",
    "y_test_pred_encoded = xgb_model.predict(X_test)\n",
    "test_df['emotion'] = label_encoder.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "# è¼¸å‡ºç‚º submission.csv\n",
    "submission = test_df[['id', 'emotion']]\n",
    "submission.to_csv('submission_fin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7869f0-8b44-4057-aed1-dcc8d2afc5c7",
   "metadata": {},
   "source": [
    "1. ä½ èªç‚ºä½¿ç”¨xgboostæ˜¯å¥½æ–¹æ³•å— é‚„æ˜¯æœ‰åˆ¥çš„æ›´å¥½çš„è¾¦æ³• codeè¦åšé‚£äº›ä¿®æ”¹\n",
    "2. ä½ èªç‚ºé™ç¶­æœƒæé«˜æœ€å¾Œçš„çµæœå— æ‡‰è©²åœ¨å“ªè£¡é™\n",
    "3. ä½ èªç‚ºå‰è™•ç†é‚„æœ‰ä»€éº¼å¯ä»¥æ›´åŠ å¼·çš„åšæ³•å— ä¾‹å¦‚æ­£å‰‡åŒ–ä¹‹é¡çš„ æˆ–æ˜¯å…¶ä»– è«‹æå‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774f8cee-32b9-4845-8b4a-e70f97acb0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a  anticipation\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80       sadness\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f       sadness\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"submission_fin.csv\")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bbfcc65-9542-4ee8-9b17-feb48ffe234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412  anticipation\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443           joy\n",
       "3       0x2939d5           joy\n",
       "4       0x26289a         trust\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e  anticipation\n",
       "411969  0x316b80           joy\n",
       "411970  0x29d0cb           joy\n",
       "411971  0x2a6a4f           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.read_csv(\"submission.csv\")\n",
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc28a3c1-d861-48e9-a0c5-232db2e39bd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# æ‰¾å‡ºå…©å€‹ column ä¸­ç¨æœ‰çš„å€¼\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m unique_to_df1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(sub1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m unique_to_df2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sub1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unique_to_df1:\n",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\users\\t1070\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# æ‰¾å‡ºå…©å€‹ column ä¸­ç¨æœ‰çš„å€¼\n",
    "unique_to_df1 = set(sub['id']) - set(sub1['id'])\n",
    "unique_to_df2 = set(sub1['id']) - set(sub['id'])\n",
    "\n",
    "if unique_to_df1:\n",
    "    print(f\"sub.csv ä¸­æœ‰ sub1.csv æ²’æœ‰çš„å€¼ï¼š{unique_to_df1}\")\n",
    "if unique_to_df2:\n",
    "    print(f\"sub1.csv çš„  column ä¸­æœ‰ sub.csv æ²’æœ‰çš„å€¼ï¼š{unique_to_df2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30b011-8854-4548-8ee5-430209e6cf24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
